{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "debfed6b-4c92-4563-9574-4a19c13c8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "tables = []\n",
    "\n",
    "with pdfplumber.open(\"Text_Data/fsae_2024_results.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        tables.append(page.extract_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0cbf19e-38aa-4d75-8405-2a8ba44dbd68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "data = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c15faf50-3f1a-4782-b14e-4f8f799cb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Table 36 is a none type :/ not sure why\n",
    "del tables[36]\n",
    "# checking the table on page 37, it seems to just be a funcky table, doesn't contain team information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e503f936-e30f-45b8-8359-2b75078d8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(tables):        \n",
    "    # File path for the CSV\n",
    "\n",
    "    csv_file_path = 'Csv_Data_w_weight/table_{}.csv'.format(i)\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bdae79a-6b4f-4a47-8ec3-1ccd329152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "def spring_cleaning(fname):\n",
    "    data = pd.read_csv(fname, header=None)\n",
    "    data.head()\n",
    "    cleaned_header = data.iloc[0].apply(lambda x: x.replace('\\n', ''))\n",
    "    data.columns = cleaned_header\n",
    "    data_cleaned = data.drop(0)\n",
    "    data_cleaned.head()\n",
    "    data_cleaned.to_csv(fname)\n",
    "\n",
    "def spring_cleaning_for_special(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df_cleaned = df.map(lambda x: x.replace('\\n', '') if isinstance(x, str) else x)\n",
    "\n",
    "def reverse_first_line_in_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    first_line = lines[0].strip().split(',')\n",
    "    reversed_first_line = [word[::-1] for word in first_line]\n",
    "\n",
    "    new_first_line = ','.join(reversed_first_line) + '\\n'\n",
    "\n",
    "    lines[0] = new_first_line\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "def reverse_first_line_in_file_for_special(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    first_line = lines[1].strip().split(',')\n",
    "    reversed_first_line = [word[::-1] for word in first_line]\n",
    "\n",
    "    new_first_line = ','.join(reversed_first_line) + '\\n'\n",
    "\n",
    "    lines[1] = new_first_line\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21b7ce8-127a-4487-b36c-7dc66f4d6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Csv_Data_w_weight/table_22.csv\n",
      "./Csv_Data_w_weight/table_10.csv\n",
      "./Csv_Data_w_weight/table_12.csv\n",
      "./Csv_Data_w_weight/table_29.csv\n",
      "./Csv_Data_w_weight/table_23.csv\n",
      "./Csv_Data_w_weight/table_28.csv\n",
      "./Csv_Data_w_weight/table_18.csv\n",
      "./Csv_Data_w_weight/table_33.csv\n",
      "./Csv_Data_w_weight/table_32.csv\n",
      "./Csv_Data_w_weight/table_4.csv\n",
      "./Csv_Data_w_weight/table_0.csv\n",
      "./Csv_Data_w_weight/table_19.csv\n",
      "./Csv_Data_w_weight/table_25.csv\n",
      "./Csv_Data_w_weight/table_31.csv\n",
      "./Csv_Data_w_weight/table_5.csv\n",
      "./Csv_Data_w_weight/table_1.csv\n",
      "./Csv_Data_w_weight/table_37.csv\n",
      "./Csv_Data_w_weight/table_20.csv\n",
      "./Csv_Data_w_weight/table_34.csv\n",
      "./Csv_Data_w_weight/table_2.csv\n",
      "./Csv_Data_w_weight/table_14.csv\n",
      "./Csv_Data_w_weight/table_11.csv\n",
      "./Csv_Data_w_weight/table_21.csv\n",
      "./Csv_Data_w_weight/table_38.csv\n",
      "./Csv_Data_w_weight/table_40.csv\n",
      "./Csv_Data_w_weight/table_9.csv\n",
      "./Csv_Data_w_weight/table_24.csv\n",
      "./Csv_Data_w_weight/table_36.csv\n",
      "./Csv_Data_w_weight/table_35.csv\n",
      "./Csv_Data_w_weight/table_27.csv\n",
      "./Csv_Data_w_weight/table_17.csv\n",
      "./Csv_Data_w_weight/table_15.csv\n",
      "./Csv_Data_w_weight/table_13.csv\n",
      "./Csv_Data_w_weight/table_16.csv\n",
      "./Csv_Data_w_weight/table_39.csv\n",
      "./Csv_Data_w_weight/table_30.csv\n",
      "./Csv_Data_w_weight/table_3.csv\n",
      "./Csv_Data_w_weight/table_6.csv\n",
      "./Csv_Data_w_weight/table_8.csv\n",
      "./Csv_Data_w_weight/table_26.csv\n",
      "./Csv_Data_w_weight/table_7.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in listdir_nohidden(\"./Csv_Data_w_weight\"):\n",
    "    try:\n",
    "        \n",
    "        spring_cleaning(os.path.join(\"./Csv_Data_w_weight\", filename))\n",
    "        print(\"One Line\")\n",
    "        print(os.path.join(\"./Csv_Data_w_weight\", filename))\n",
    "        reverse_first_line_in_file(os.path.join(\"./Csv_Data_w_weight\", filename))\n",
    "    except:\n",
    "        df = pd.read_csv((os.path.join(\"./Csv_Data_w_weight\", filename)))\n",
    "        print(\"two line\")\n",
    "        print(os.path.join(\"./Csv_Data_w_weight\", filename))\n",
    "        df_cleaned = df.map(lambda x: x.replace('\\n', '') if isinstance(x, str) else x)\n",
    "        \n",
    "        df_cleaned.to_csv(os.path.join(\"./Csv_Data_w_weight\", filename), index=False)\n",
    "        reverse_first_line_in_file_for_special(os.path.join(\"./Csv_Data_w_weight\", filename))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
